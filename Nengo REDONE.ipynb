{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac118d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hahah :)\n",
    "# https://github.com/H-Elbez/Nengo\n",
    "# Let's see if that does ANYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc45afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just rebuild the entire thing,\n",
    "# I kinda don't want to mess with the other version\n",
    "\n",
    "# Don't be nervous about doing wrong things in here! \n",
    "# See it as a draft version, or a messing around version, you can make a clean version of this later\n",
    "# These are safe testing grounds where we mess around with a lot of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d412923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "from STDP_learning import STDP\n",
    "from DataLog import DataLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54922b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkShape(var, kernel):\n",
    "    '''Check shapes for convolution\n",
    "    Args:\n",
    "        var (ndarray): 2d or 3d input array for convolution.\n",
    "        kernel (ndarray): 2d or 3d convolution kernel.\n",
    "    Returns:\n",
    "        kernel (ndarray): 2d kernel reshape into 3d if needed.\n",
    "    '''\n",
    "    var_ndim = np.ndim(var)\n",
    "    kernel_ndim = np.ndim(kernel)\n",
    "    if var_ndim not in [2, 3]:\n",
    "        raise Exception(\"<var> dimension should be in 2 or 3.\")\n",
    "    if kernel_ndim not in [2, 3]:\n",
    "        raise Exception(\"<kernel> dimension should be in 2 or 3.\")\n",
    "    if var_ndim < kernel_ndim:\n",
    "        raise Exception(\"<kernel> dimension > <var>.\")\n",
    "    if var_ndim == 3 and kernel_ndim == 2:\n",
    "        kernel = np.repeat(kernel[:, :, None], var.shape[2], axis=2)\n",
    "    return kernel\n",
    "\n",
    "def asStride(arr, sub_shape, stride):\n",
    "    '''Get a strided sub-matrices view of an ndarray.\n",
    "    Args:\n",
    "        arr (ndarray): input array of rank 2 or 3, with shape (m1, n1) or (m1, n1, c).\n",
    "        sub_shape (tuple): window size: (m2, n2).\n",
    "        stride (int): stride of windows in both y- and x- dimensions.\n",
    "    Returns:\n",
    "        subs (view): strided window view.\n",
    "    See also skimage.util.shape.view_as_windows()\n",
    "    '''\n",
    "    s0, s1 = arr.strides[:2]\n",
    "    m1, n1 = arr.shape[:2]\n",
    "    m2, n2 = sub_shape[:2]\n",
    "    view_shape = (1+(m1-m2)//stride, 1+(n1-n2)//stride, m2, n2)+arr.shape[2:]\n",
    "    strides = (stride*s0, stride*s1, s0, s1)+arr.strides[2:]\n",
    "    subs = np.lib.stride_tricks.as_strided(\n",
    "        arr, view_shape, strides=strides, writeable=False)\n",
    "    return subs\n",
    "\n",
    "def conv3D3(var, kernel, stride=1, pad=0):\n",
    "    '''3D convolution by strided view.\n",
    "    Args:\n",
    "        var (ndarray): 2d or 3d array to convolve along the first 2 dimensions.\n",
    "        kernel (ndarray): 2d or 3d kernel to convolve. If <var> is 3d and <kernel>\n",
    "            is 2d, create a dummy dimension to be the 3rd dimension in kernel.\n",
    "    Keyword Args:\n",
    "        stride (int): stride along the 1st 2 dimensions. Default to 1.\n",
    "        pad (int): number of columns/rows to pad at edges.\n",
    "    Returns:\n",
    "        conv (ndarray): convolution result.\n",
    "    '''\n",
    "    kernel = checkShape(var, kernel)\n",
    "    if pad > 0:\n",
    "        var_pad = padArray(var, pad, pad)\n",
    "    else:\n",
    "        var_pad = var\n",
    "    view = asStride(var_pad, kernel.shape, stride)\n",
    "    if np.ndim(kernel) == 2:\n",
    "        conv = np.sum(view*kernel, axis=(2, 3))\n",
    "    else:\n",
    "        conv = np.sum(view*kernel, axis=(2, 3, 4))\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "158e5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters from the paper\n",
    "n_freqbands = 40\n",
    "n_timeframes = 41\n",
    "n_timesteps = 30\n",
    "\n",
    "n_neurons = n_freqbands * n_timeframes * n_timesteps\n",
    "\n",
    "n_samples = 2464\n",
    "\n",
    "f_maps = 50\n",
    "\n",
    "window_size = [6,n_freqbands]\n",
    "conv_inp_shape = (n_freqbands, n_timeframes, n_timesteps)\n",
    "stride = [1,1]\n",
    "\n",
    "mean = 0.8\n",
    "std = 0.05\n",
    "\n",
    "LIMIT_TEST = 250\n",
    "\n",
    "presentation_time = 0.001\n",
    "\n",
    "threshold = 23\n",
    "thresh_config = nengo.presets.ThresholdingEnsembles(threshold) # Set the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73d3f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train = np.load(\"spike_trains_train_fixed2.npy\")\n",
    "\n",
    "# [n_freqbands* n_timeframes * n_timesteps, n_samples] or in other words [data, n_samples]\n",
    "# train = np.reshape(train, (n_freqbands*n_timeframes*n_timesteps, n_samples))\n",
    "\n",
    "# train = train[:,0:LIMIT_TEST]\n",
    "\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "097be9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conv = np.reshape(train, (40,41,30,2464))\n",
    "train_new = []\n",
    "\n",
    "for n in range(n_samples):\n",
    "    train_new.append(conv3D3(train_conv[:,:,:,n], np.array([[40,6]])))\n",
    "    \n",
    "train_new = np.array(train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4b08ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 2464)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "437a32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = np.reshape(train_new.T, (1600,2464))[:,0:LIMIT_TEST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54d55cdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 2.464 seconds\n",
      "Build finished in 0:00:00                                                      \n",
      "Optimization finished in 0:00:00                                               \n",
      "Construction finished in 0:00:00                                               \n",
      "Simulation finished in 0:00:14                                                 \n",
      "CPU times: total: 22.7 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = nengo.Network(label=\"Audio STDP learning\")\n",
    "\n",
    "# Log and reduce collected Probes to avoid getting memory issues\n",
    "full_log = False\n",
    "\n",
    "if(not full_log):\n",
    "    log = DataLog()\n",
    "\n",
    "with model:\n",
    "\n",
    "    # Layers ----------------------------------------------------------------------\n",
    "    input_layer = nengo.Node(nengo.processes.PresentInput(train_new, presentation_time))\n",
    "    \n",
    "    pre = nengo.Ensemble(LIMIT_TEST, dimensions=LIMIT_TEST)\n",
    "    \n",
    "    post = nengo.Ensemble(LIMIT_TEST, dimensions=LIMIT_TEST)\n",
    "    \n",
    "    # Transformations -------------------------------------------------------------\n",
    "#     transform = nengo.Convolution(\n",
    "#                 n_filters = f_maps,\n",
    "#                 input_shape = conv_inp_shape,\n",
    "#                 kernel_size = window_size,\n",
    "#                 strides = stride,\n",
    "#                 padding=\"valid\", # previously: \"same\"\n",
    "#                 channels_last = True,\n",
    "#                 init = nengo.dists.Gaussian(mean, std)\n",
    "#             )\n",
    "    \n",
    "    # Connections -----------------------------------------------------------------\n",
    "    \n",
    "#     conv_conn = nengo.Connection(input_layer, pre, transform = transform)\n",
    "    \n",
    "    learn_conn = nengo.Connection(\n",
    "        pre, post,\n",
    "        learning_rule_type = nengo.BCM(learning_rate=5e-10), # Change this later\n",
    "        solver = nengo.solvers.LstsqL2(weights=True)\n",
    "    )\n",
    "    \n",
    "    # Probes ----------------------------------------------------------------------\n",
    "#     input_probe = nengo.Probe(input_layer)\n",
    "    \n",
    "#     pre_probe = nengo.Probe(pre, synapse=0.01) # Do these make sense...?\n",
    "#     post_probe = nengo.Probe(post, synapse=0.01)\n",
    "    \n",
    "    layer1_synapses_probe = nengo.Probe(learn_conn,\"weights\",label=\"layer1_synapses\") # This seems to be a very big one, that those other people make the heatmap from\n",
    "    \n",
    "    if(not full_log):\n",
    "        nengo.Node(log)\n",
    "    \n",
    "print(\"Running for {} seconds\".format(len(train)*presentation_time))\n",
    "with nengo_dl.Simulator(model) as sim:\n",
    "        \n",
    "    sim.run(len(train)*presentation_time) # This makes sense right, since you're now presenting every point for 0.1 second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a96cc00a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 453 ms\n",
      "Wall time: 456 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2464, 250, 250)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sim.data[layer1_synapses_probe].shape\n",
    "\n",
    "# sum(sim.data[layer1_synapses_probe][:,0,:])\n",
    "\n",
    "# with open('weights.npy', 'wb') as f:\n",
    "#     np.save(f, sim.data[layer1_synapses_probe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8be893be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_output = sim.data[layer1_synapses_probe]\n",
    "\n",
    "avg = sum(sample_output)/sample_output.shape[1]\n",
    "\n",
    "avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a914bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10675056, 0.08300735, 0.1355629 , ..., 0.08745863, 0.00063955,\n",
       "        0.13214238],\n",
       "       [0.10887646, 0.08229525, 0.1413293 , ..., 0.08850267, 0.00482082,\n",
       "        0.13497776],\n",
       "       [0.1107283 , 0.08471756, 0.14173488, ..., 0.10700819, 0.00025525,\n",
       "        0.1321756 ],\n",
       "       ...,\n",
       "       [0.10842292, 0.09115589, 0.14779562, ..., 0.1199377 , 0.00371732,\n",
       "        0.14109948],\n",
       "       [0.10463195, 0.08498006, 0.13435507, ..., 0.08810836, 0.00025392,\n",
       "        0.12172994],\n",
       "       [0.09835338, 0.07705263, 0.12826617, ..., 0.08532179, 0.04395097,\n",
       "        0.1198554 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled = block_reduce(avg, (4), np.max)\n",
    "\n",
    "pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6ec8626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(50):\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804edeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a silly thing I do so the notebook let's me scroll down :p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
